"""
Redis ìºì‹± ì‹œìŠ¤í…œ ì‹¤ì œ ì ìš© ìƒíƒœ í™•ì¸
main.py ì‹¤í–‰ í™˜ê²½ì—ì„œì˜ ì‹¤ì œ ìºì‹± ë™ì‘ ê²€ì¦
"""

import sys
import time
import logging
import os
from pathlib import Path
from typing import Dict, List, Any
import json

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-8s | %(message)s'
)

class RedisProductionVerifier:
    """Redis ìºì‹± ì‹œìŠ¤í…œ í”„ë¡œë•ì…˜ í™˜ê²½ ê²€ì¦ê¸°"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.verification_results = {}
    
    def test_redis_in_main_context(self) -> Dict[str, Any]:
        """main.py ì»¨í…ìŠ¤íŠ¸ì—ì„œ Redis ìºì‹± í…ŒìŠ¤íŠ¸"""
        self.logger.info("1. main.py ì»¨í…ìŠ¤íŠ¸ì—ì„œ Redis ìºì‹± í…ŒìŠ¤íŠ¸")
        
        test_results = {
            'main_import_success': False,
            'phase3_integration_active': False,
            'redis_cache_working': False,
            'memory_fallback_working': False,
            'cache_statistics_collected': False,
            'error_details': None
        }
        
        try:
            # main.pyì—ì„œ Phase 3 í†µí•© ìƒíƒœ í™•ì¸
            from main import PHASE3_INTEGRATION_AVAILABLE, DBExcelEditor
            test_results['main_import_success'] = True
            test_results['phase3_integration_active'] = PHASE3_INTEGRATION_AVAILABLE
            
            if PHASE3_INTEGRATION_AVAILABLE:
                # Phase 3 í†µí•© ëª¨ë“ˆ import
                from ui_backend_integration_strategy import inject_phase3_into_existing_class
                
                # í…ŒìŠ¤íŠ¸ìš© DBExcelEditor ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                # (ì‹¤ì œ UI ì´ˆê¸°í™” ì—†ì´ ë°±ì—”ë“œë§Œ í…ŒìŠ¤íŠ¸)
                class TestDBExcelEditor:
                    def __init__(self):
                        pass
                
                # Phase 3 ê¸°ëŠ¥ ì£¼ì…
                inject_phase3_into_existing_class(TestDBExcelEditor)
                test_editor = TestDBExcelEditor()
                
                # Phase 3 ë°±ì—”ë“œ í™•ì¸
                if hasattr(test_editor, 'phase3_backend') and test_editor.phase3_backend:
                    # ìºì‹± í”„ë¡œì„¸ì„œ í™•ì¸
                    cached_processor = test_editor.phase3_backend._cached_processor
                    
                    if cached_processor:
                        # ìºì‹œ í…ŒìŠ¤íŠ¸ ë°ì´í„°
                        test_key = "redis_production_test"
                        test_value = [["DEFINE", "CONST", "FLOAT32", "REDIS_TEST", "1.0", "Redis Production Test"]]
                        
                        # ìºì‹œ ì €ì¥/ì¡°íšŒ í…ŒìŠ¤íŠ¸
                        cached_processor.set_to_cache(test_key, test_value)
                        retrieved_value = cached_processor.get_from_cache(test_key)
                        
                        if retrieved_value == test_value:
                            test_results['memory_fallback_working'] = True
                            self.logger.info("âœ… ë©”ëª¨ë¦¬ ìºì‹œ fallback ì •ìƒ ì‘ë™")
                        
                        # ìºì‹œ í†µê³„ ìˆ˜ì§‘ í™•ì¸
                        cache_stats = cached_processor.get_cache_stats()
                        if cache_stats and 'cache_hits' in cache_stats:
                            test_results['cache_statistics_collected'] = True
                            self.logger.info(f"âœ… ìºì‹œ í†µê³„ ìˆ˜ì§‘ í™•ì¸: {cache_stats}")
                        
                        # Redis ì—°ê²° í…ŒìŠ¤íŠ¸ (ìˆë‹¤ë©´)
                        if hasattr(cached_processor, 'redis_cache') and cached_processor.redis_cache:
                            try:
                                # Redis í…ŒìŠ¤íŠ¸
                                cached_processor.redis_cache.set_cache(test_key, test_value)
                                redis_retrieved = cached_processor.redis_cache.get_cache(test_key)
                                if redis_retrieved == test_value:
                                    test_results['redis_cache_working'] = True
                                    self.logger.info("âœ… Redis ìºì‹œ ì •ìƒ ì‘ë™")
                            except Exception as e:
                                self.logger.info(f"â„¹ï¸ Redis ìºì‹œ ì—†ìŒ (ë©”ëª¨ë¦¬ ìºì‹œë¡œ ëŒ€ì²´): {e}")
                
                self.logger.info("âœ… main.py ì»¨í…ìŠ¤íŠ¸ì—ì„œ ìºì‹± ì‹œìŠ¤í…œ ê²€ì¦ ì™„ë£Œ")
            else:
                test_results['error_details'] = "Phase 3 í†µí•©ì´ ë¹„í™œì„±í™”ë¨"
                
        except Exception as e:
            test_results['error_details'] = str(e)
            self.logger.error(f"âŒ main.py ì»¨í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
        return test_results
    
    def test_cache_hit_miss_statistics(self) -> Dict[str, Any]:
        """ìºì‹œ íˆíŠ¸/ë¯¸ìŠ¤ í†µê³„ ì‹¤ì œ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸"""
        self.logger.info("2. ìºì‹œ íˆíŠ¸/ë¯¸ìŠ¤ í†µê³„ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸")
        
        stats_results = {
            'statistics_working': False,
            'hit_miss_tracking': False,
            'performance_measurement': False,
            'cache_efficiency': 0.0,
            'detailed_stats': {}
        }
        
        try:
            from cached_db_processor import CachedDBProcessor, CacheConfig
            
            # ìºì‹± í”„ë¡œì„¸ì„œ ìƒì„±
            config = CacheConfig(
                enable_memory_cache=True,
                memory_cache_size=100,
                enable_redis_cache=False  # ë©”ëª¨ë¦¬ ìºì‹œë§Œ í…ŒìŠ¤íŠ¸
            )
            
            processor = CachedDBProcessor(config)
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
            test_data = []
            for i in range(20):
                test_data.append([
                    "DEFINE", "CONST", "FLOAT32", 
                    f"TEST_VAR_{i}", f"{i}.0", f"Test variable {i}"
                ])
            
            # ì²« ë²ˆì§¸ ì‹¤í–‰ (ìºì‹œ ë¯¸ìŠ¤)
            test_key_1 = "stats_test_1"
            start_time = time.perf_counter()
            processor.set_to_cache(test_key_1, test_data)
            first_set_time = time.perf_counter() - start_time
            
            # ì²« ë²ˆì§¸ ì¡°íšŒ (ìºì‹œ íˆíŠ¸)
            start_time = time.perf_counter()
            retrieved_1 = processor.get_from_cache(test_key_1)
            first_get_time = time.perf_counter() - start_time
            
            # ë‘ ë²ˆì§¸ ì¡°íšŒ (ìºì‹œ íˆíŠ¸)
            start_time = time.perf_counter()
            retrieved_2 = processor.get_from_cache(test_key_1)
            second_get_time = time.perf_counter() - start_time
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í‚¤ ì¡°íšŒ (ìºì‹œ ë¯¸ìŠ¤)
            start_time = time.perf_counter()
            retrieved_none = processor.get_from_cache("nonexistent_key")
            miss_time = time.perf_counter() - start_time
            
            # í†µê³„ ìˆ˜ì§‘
            cache_stats = processor.get_cache_stats()
            
            if cache_stats:
                stats_results['statistics_working'] = True
                stats_results['detailed_stats'] = cache_stats
                
                # íˆíŠ¸/ë¯¸ìŠ¤ ì¶”ì  í™•ì¸
                if 'cache_hits' in cache_stats and 'cache_misses' in cache_stats:
                    stats_results['hit_miss_tracking'] = True
                    
                    total_requests = cache_stats['cache_hits'] + cache_stats['cache_misses']
                    if total_requests > 0:
                        stats_results['cache_efficiency'] = cache_stats['cache_hits'] / total_requests * 100
                
                # ì„±ëŠ¥ ì¸¡ì • í™•ì¸
                if first_get_time < first_set_time:  # ì¡°íšŒê°€ ì €ì¥ë³´ë‹¤ ë¹ ë¥´ë©´ ì •ìƒ
                    stats_results['performance_measurement'] = True
                
                self.logger.info(f"âœ… ìºì‹œ í†µê³„: {cache_stats}")
                self.logger.info(f"âœ… ìºì‹œ íš¨ìœ¨: {stats_results['cache_efficiency']:.1f}%")
            
            processor.cleanup()
            
        except Exception as e:
            stats_results['error'] = str(e)
            self.logger.error(f"âŒ ìºì‹œ í†µê³„ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
        return stats_results
    
    def test_memory_fallback_mechanism(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ìºì‹œ fallback ë©”ì»¤ë‹ˆì¦˜ í…ŒìŠ¤íŠ¸"""
        self.logger.info("3. ë©”ëª¨ë¦¬ ìºì‹œ fallback ë©”ì»¤ë‹ˆì¦˜ í…ŒìŠ¤íŠ¸")
        
        fallback_results = {
            'redis_connection_failed': False,
            'memory_fallback_activated': False,
            'data_consistency_maintained': False,
            'performance_acceptable': False,
            'fallback_stats': {}
        }
        
        try:
            from cached_db_processor import CachedDBProcessor, CacheConfig
            
            # Redis ì—°ê²° ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜ (ì˜ëª»ëœ ì„¤ì •)
            config_with_redis_fail = CacheConfig(
                enable_redis_cache=True,
                enable_memory_cache=True,
                memory_cache_size=100,
                redis_host='nonexistent_host',
                redis_port=9999
            )
            
            processor = CachedDBProcessor(config_with_redis_fail)
            
            # Redis ì—°ê²° ì‹¤íŒ¨ í™•ì¸
            if not hasattr(processor, 'redis_cache') or not processor.redis_cache or not processor.redis_cache.redis_client:
                fallback_results['redis_connection_failed'] = True
                self.logger.info("âœ… Redis ì—°ê²° ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜ ì„±ê³µ")
            
            # ë©”ëª¨ë¦¬ ìºì‹œë¡œ fallback í…ŒìŠ¤íŠ¸
            test_data = [["DEFINE", "CONST", "INT32", "FALLBACK_TEST", "42", "Fallback Test"]]
            test_key = "fallback_test_key"
            
            # ì €ì¥ í…ŒìŠ¤íŠ¸
            start_time = time.perf_counter()
            processor.set_to_cache(test_key, test_data)
            set_time = time.perf_counter() - start_time
            
            # ì¡°íšŒ í…ŒìŠ¤íŠ¸
            start_time = time.perf_counter()
            retrieved_data = processor.get_from_cache(test_key)
            get_time = time.perf_counter() - start_time
            
            # ë°ì´í„° ì¼ê´€ì„± í™•ì¸
            if retrieved_data == test_data:
                fallback_results['memory_fallback_activated'] = True
                fallback_results['data_consistency_maintained'] = True
                self.logger.info("âœ… ë©”ëª¨ë¦¬ fallback ë°ì´í„° ì¼ê´€ì„± í™•ì¸")
            
            # ì„±ëŠ¥ í™•ì¸ (ë©”ëª¨ë¦¬ ìºì‹œëŠ” ì¶©ë¶„íˆ ë¹¨ë¼ì•¼ í•¨)
            if get_time < 0.001:  # 1ms ì´í•˜
                fallback_results['performance_acceptable'] = True
                self.logger.info(f"âœ… ë©”ëª¨ë¦¬ fallback ì„±ëŠ¥ ì–‘í˜¸: {get_time*1000:.3f}ms")
            
            # Fallback í†µê³„
            fallback_stats = processor.get_cache_stats()
            if fallback_stats:
                fallback_results['fallback_stats'] = fallback_stats
            
            processor.cleanup()
            
        except Exception as e:
            fallback_results['error'] = str(e)
            self.logger.error(f"âŒ ë©”ëª¨ë¦¬ fallback í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        
        return fallback_results
    
    def generate_redis_verification_report(self) -> Dict[str, Any]:
        """Redis ìºì‹± ì‹œìŠ¤í…œ ê²€ì¦ ë³´ê³ ì„œ ìƒì„±"""
        self.logger.info("Redis ìºì‹± ì‹œìŠ¤í…œ ì‹¤ì œ ì ìš© ìƒíƒœ ê²€ì¦ ì‹œì‘")
        
        # ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        main_context_test = self.test_redis_in_main_context()
        statistics_test = self.test_cache_hit_miss_statistics()
        fallback_test = self.test_memory_fallback_mechanism()
        
        # ì¢…í•© í‰ê°€
        total_tests = 6
        passed_tests = 0
        
        # main.py ì»¨í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸
        if main_context_test.get('phase3_integration_active', False):
            passed_tests += 1
        if main_context_test.get('memory_fallback_working', False):
            passed_tests += 1
        
        # í†µê³„ í…ŒìŠ¤íŠ¸
        if statistics_test.get('statistics_working', False):
            passed_tests += 1
        if statistics_test.get('hit_miss_tracking', False):
            passed_tests += 1
        
        # Fallback í…ŒìŠ¤íŠ¸
        if fallback_test.get('memory_fallback_activated', False):
            passed_tests += 1
        if fallback_test.get('data_consistency_maintained', False):
            passed_tests += 1
        
        verification_score = (passed_tests / total_tests) * 100
        
        verification_report = {
            'overall_verification_score': verification_score,
            'tests_passed': passed_tests,
            'total_tests': total_tests,
            'main_context_test': main_context_test,
            'statistics_test': statistics_test,
            'fallback_test': fallback_test,
            'summary': {
                'redis_production_ready': main_context_test.get('phase3_integration_active', False),
                'cache_statistics_working': statistics_test.get('statistics_working', False),
                'fallback_mechanism_reliable': fallback_test.get('data_consistency_maintained', False),
                'overall_cache_efficiency': statistics_test.get('cache_efficiency', 0.0)
            }
        }
        
        return verification_report

def main():
    """Redis ìºì‹± ì‹œìŠ¤í…œ ì‹¤ì œ ì ìš© ìƒíƒœ ê²€ì¦ ì‹¤í–‰"""
    print("ğŸ” Redis ìºì‹± ì‹œìŠ¤í…œ ì‹¤ì œ ì ìš© ìƒíƒœ ê²€ì¦")
    print("=" * 80)
    
    verifier = RedisProductionVerifier()
    
    try:
        # Redis ê²€ì¦ ì‹¤í–‰
        report = verifier.generate_redis_verification_report()
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š Redis ìºì‹± ì‹œìŠ¤í…œ ê²€ì¦ ê²°ê³¼:")
        print(f"   ê²€ì¦ ì ìˆ˜: {report['overall_verification_score']:.1f}% ({report['tests_passed']}/{report['total_tests']})")
        
        # ì£¼ìš” ê²°ê³¼
        summary = report['summary']
        print(f"\nğŸ” ì£¼ìš” ê²€ì¦ ê²°ê³¼:")
        print(f"   í”„ë¡œë•ì…˜ ì¤€ë¹„: {'âœ…' if summary['redis_production_ready'] else 'âŒ'}")
        print(f"   ìºì‹œ í†µê³„ ìˆ˜ì§‘: {'âœ…' if summary['cache_statistics_working'] else 'âŒ'}")
        print(f"   Fallback ì‹ ë¢°ì„±: {'âœ…' if summary['fallback_mechanism_reliable'] else 'âŒ'}")
        print(f"   ìºì‹œ íš¨ìœ¨: {summary['overall_cache_efficiency']:.1f}%")
        
        # ìƒì„¸ ê²°ê³¼
        print(f"\nğŸ“‹ ìƒì„¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        
        main_test = report['main_context_test']
        print(f"   main.py ì»¨í…ìŠ¤íŠ¸: {'âœ…' if main_test.get('phase3_integration_active') else 'âŒ'}")
        if main_test.get('memory_fallback_working'):
            print(f"     ë©”ëª¨ë¦¬ ìºì‹œ: âœ… ì •ìƒ ì‘ë™")
        
        stats_test = report['statistics_test']
        if stats_test.get('detailed_stats'):
            stats = stats_test['detailed_stats']
            print(f"   ìºì‹œ í†µê³„: âœ… ìˆ˜ì§‘ ì¤‘")
            print(f"     íˆíŠ¸: {stats.get('cache_hits', 0)}íšŒ")
            print(f"     ë¯¸ìŠ¤: {stats.get('cache_misses', 0)}íšŒ")
            print(f"     í¬ê¸°: {stats.get('cache_size', 0)}/{stats.get('max_size', 0)}")
        
        fallback_test = report['fallback_test']
        if fallback_test.get('fallback_stats'):
            print(f"   Fallback í†µê³„: âœ… ì •ìƒ")
        
        # ê²°ê³¼ ì €ì¥
        with open('redis_production_verification_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ ìƒì„¸ ë³´ê³ ì„œê°€ 'redis_production_verification_report.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"âŒ Redis ê²€ì¦ ì‹¤íŒ¨: {e}")
        logging.error(f"Redis ê²€ì¦ ì‹¤íŒ¨: {e}")
    
    print("=" * 80)

if __name__ == "__main__":
    main()
