"""
DB â†’ C ì½”ë“œ ë³€í™˜ ì„±ëŠ¥ ë¬¸ì œ ë¶„ì„ê¸°
ì¼ê´„ ì²˜ë¦¬ vs ê°œë³„ ì²˜ë¦¬ ì„±ëŠ¥ ë¹„êµ ë° ë³‘ëª© ì§€ì  ì‹ë³„
"""

import time
import psutil
import gc
import logging
import os
import sys
from pathlib import Path
from typing import Dict, List, Any, Tuple
import json
import traceback
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import threading

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-8s | %(message)s'
)

class DBToCodePerformanceAnalyzer:
    """DB â†’ C ì½”ë“œ ë³€í™˜ ì„±ëŠ¥ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.process = psutil.Process()
        self.analysis_results = {}
        self.db_files = []
        
    def discover_db_files(self) -> List[Path]:
        """DB íŒŒì¼ ë°œê²¬ ë° ë¶„ì„"""
        print("ğŸ” DB íŒŒì¼ ë°œê²¬ ë° ë¶„ì„")
        print("=" * 60)
        
        db_dir = Path('database')
        if not db_dir.exists():
            print("âŒ Database ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return []
        
        db_files = list(db_dir.glob('*.db'))
        print(f"ğŸ“ ë°œê²¬ëœ DB íŒŒì¼: {len(db_files)}ê°œ")
        
        # DB íŒŒì¼ ìƒì„¸ ì •ë³´ ë¶„ì„
        for i, db_file in enumerate(db_files):
            file_size = db_file.stat().st_size
            print(f"   {i+1}. {db_file.name} ({file_size:,} bytes)")
            
            # DB ë‚´ìš© ê°„ë‹¨ ë¶„ì„
            try:
                from data_manager.db_handler_v2 import DBHandlerV2
                db_handler = DBHandlerV2(str(db_file))
                db_handler.connect()
                
                sheets = db_handler.get_sheets()
                dollar_sheets = [s for s in sheets if s.get('is_dollar_sheet', False)]
                
                total_cells = 0
                for sheet in dollar_sheets:
                    sheet_data = db_handler.get_sheet_data(sheet['id'])
                    if sheet_data:
                        total_cells += len(sheet_data)
                
                print(f"      ì‹œíŠ¸: {len(sheets)}ê°œ ($ ì‹œíŠ¸: {len(dollar_sheets)}ê°œ)")
                print(f"      ì…€ ë°ì´í„°: {total_cells:,}ê°œ")
                
                db_handler.disconnect()
                
            except Exception as e:
                print(f"      âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        self.db_files = db_files[:5]  # ìµœëŒ€ 5ê°œ íŒŒì¼
        return self.db_files
    
    def measure_memory_and_cpu(self) -> Dict[str, float]:
        """ë©”ëª¨ë¦¬ ë° CPU ì‚¬ìš©ëŸ‰ ì¸¡ì •"""
        memory_info = self.process.memory_info()
        cpu_percent = self.process.cpu_percent()
        
        return {
            'rss_mb': memory_info.rss / 1024 / 1024,
            'vms_mb': memory_info.vms / 1024 / 1024,
            'cpu_percent': cpu_percent
        }
    
    def convert_single_db_to_code(self, db_file: Path) -> Dict[str, Any]:
        """ë‹¨ì¼ DB íŒŒì¼ì„ C ì½”ë“œë¡œ ë³€í™˜"""
        print(f"\nğŸ”„ ë‹¨ì¼ ë³€í™˜: {db_file.name}")
        
        start_memory = self.measure_memory_and_cpu()
        start_time = time.perf_counter()
        
        try:
            from data_manager.db_handler_v2 import DBHandlerV2
            from cython_extensions.code_generator_v2 import fast_write_cal_list_processing
            
            # DB ì—°ê²°
            db_handler = DBHandlerV2(str(db_file))
            db_handler.connect()
            
            # $ ì‹œíŠ¸ ì°¾ê¸°
            sheets = db_handler.get_sheets()
            dollar_sheets = [s for s in sheets if s.get('is_dollar_sheet', False)]
            
            total_processed_items = 0
            step_times = {}
            
            # ë‹¨ê³„ë³„ ì‹œê°„ ì¸¡ì •
            step_start = time.perf_counter()
            
            for sheet in dollar_sheets:
                sheet_data = db_handler.get_sheet_data(sheet['id'])
                if sheet_data:
                    # ì½”ë“œ ì•„ì´í…œ ìƒì„±
                    code_items = []
                    for row_data in sheet_data:
                        if len(row_data) >= 3:
                            code_items.append([
                                "DEFINE", "CONST", "FLOAT32",
                                f"VAL_{row_data[0]}_{row_data[1]}", 
                                str(row_data[2]) if row_data[2] else "",
                                f"Generated from {sheet['name']}"
                            ])
                    
                    # Cython ì½”ë“œ ìƒì„±
                    processed_code = fast_write_cal_list_processing(code_items)
                    total_processed_items += len(processed_code)
            
            step_times['code_generation'] = time.perf_counter() - step_start
            
            # DB ì—°ê²° í•´ì œ
            db_handler.disconnect()
            
            end_time = time.perf_counter()
            end_memory = self.measure_memory_and_cpu()
            
            execution_time = end_time - start_time
            memory_delta = end_memory['rss_mb'] - start_memory['rss_mb']
            
            result = {
                'success': True,
                'execution_time': execution_time,
                'processed_items': total_processed_items,
                'memory_delta_mb': memory_delta,
                'start_memory_mb': start_memory['rss_mb'],
                'end_memory_mb': end_memory['rss_mb'],
                'step_times': step_times,
                'file_name': db_file.name
            }
            
            print(f"   âœ… ì™„ë£Œ: {execution_time:.3f}ì´ˆ, {total_processed_items:,}ê°œ í•­ëª©")
            print(f"   ğŸ“Š ë©”ëª¨ë¦¬: {start_memory['rss_mb']:.1f}MB â†’ {end_memory['rss_mb']:.1f}MB (+{memory_delta:.1f}MB)")
            
            return result
            
        except Exception as e:
            print(f"   âŒ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'file_name': db_file.name
            }
    
    def convert_batch_db_to_code(self, db_files: List[Path]) -> Dict[str, Any]:
        """ì¼ê´„ DB íŒŒì¼ì„ C ì½”ë“œë¡œ ë³€í™˜"""
        print(f"\nğŸ”„ ì¼ê´„ ë³€í™˜: {len(db_files)}ê°œ íŒŒì¼")
        
        start_memory = self.measure_memory_and_cpu()
        start_time = time.perf_counter()
        
        try:
            from data_manager.db_handler_v2 import DBHandlerV2
            from cython_extensions.code_generator_v2 import fast_write_cal_list_processing
            
            total_processed_items = 0
            file_results = []
            step_times = {}
            
            for i, db_file in enumerate(db_files):
                file_start_time = time.perf_counter()
                file_start_memory = self.measure_memory_and_cpu()
                
                print(f"   ğŸ“ ì²˜ë¦¬ ì¤‘ ({i+1}/{len(db_files)}): {db_file.name}")
                
                # DB ì—°ê²°
                db_handler = DBHandlerV2(str(db_file))
                db_handler.connect()
                
                # $ ì‹œíŠ¸ ì°¾ê¸°
                sheets = db_handler.get_sheets()
                dollar_sheets = [s for s in sheets if s.get('is_dollar_sheet', False)]
                
                file_processed_items = 0
                
                for sheet in dollar_sheets:
                    sheet_data = db_handler.get_sheet_data(sheet['id'])
                    if sheet_data:
                        # ì½”ë“œ ì•„ì´í…œ ìƒì„±
                        code_items = []
                        for row_data in sheet_data:
                            if len(row_data) >= 3:
                                code_items.append([
                                    "DEFINE", "CONST", "FLOAT32",
                                    f"VAL_{row_data[0]}_{row_data[1]}", 
                                    str(row_data[2]) if row_data[2] else "",
                                    f"Generated from {sheet['name']}"
                                ])
                        
                        # Cython ì½”ë“œ ìƒì„±
                        processed_code = fast_write_cal_list_processing(code_items)
                        file_processed_items += len(processed_code)
                
                # DB ì—°ê²° í•´ì œ
                db_handler.disconnect()
                
                file_end_time = time.perf_counter()
                file_end_memory = self.measure_memory_and_cpu()
                
                file_execution_time = file_end_time - file_start_time
                file_memory_delta = file_end_memory['rss_mb'] - file_start_memory['rss_mb']
                
                file_results.append({
                    'file_name': db_file.name,
                    'execution_time': file_execution_time,
                    'processed_items': file_processed_items,
                    'memory_delta_mb': file_memory_delta
                })
                
                total_processed_items += file_processed_items
                
                print(f"      âœ… {file_execution_time:.3f}ì´ˆ, {file_processed_items:,}ê°œ í•­ëª©, ë©”ëª¨ë¦¬ +{file_memory_delta:.1f}MB")
                
                # ì¤‘ê°„ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
                gc.collect()
            
            end_time = time.perf_counter()
            end_memory = self.measure_memory_and_cpu()
            
            execution_time = end_time - start_time
            memory_delta = end_memory['rss_mb'] - start_memory['rss_mb']
            
            result = {
                'success': True,
                'execution_time': execution_time,
                'processed_items': total_processed_items,
                'memory_delta_mb': memory_delta,
                'start_memory_mb': start_memory['rss_mb'],
                'end_memory_mb': end_memory['rss_mb'],
                'file_results': file_results,
                'files_count': len(db_files)
            }
            
            print(f"\n   âœ… ì¼ê´„ ë³€í™˜ ì™„ë£Œ: {execution_time:.3f}ì´ˆ")
            print(f"   ğŸ“Š ì´ ì²˜ë¦¬: {total_processed_items:,}ê°œ í•­ëª©")
            print(f"   ğŸ“Š ë©”ëª¨ë¦¬: {start_memory['rss_mb']:.1f}MB â†’ {end_memory['rss_mb']:.1f}MB (+{memory_delta:.1f}MB)")
            
            return result
            
        except Exception as e:
            print(f"   âŒ ì¼ê´„ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'files_count': len(db_files)
            }
    
    def compare_performance(self) -> Dict[str, Any]:
        """ê°œë³„ vs ì¼ê´„ ì²˜ë¦¬ ì„±ëŠ¥ ë¹„êµ"""
        print("\nğŸ“Š ê°œë³„ vs ì¼ê´„ ì²˜ë¦¬ ì„±ëŠ¥ ë¹„êµ")
        print("=" * 60)
        
        if not self.db_files:
            print("âŒ ë¶„ì„í•  DB íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return {}
        
        # ê°œë³„ ì²˜ë¦¬ ì„±ëŠ¥ ì¸¡ì •
        print("\nğŸ”„ ê°œë³„ ì²˜ë¦¬ ì„±ëŠ¥ ì¸¡ì •")
        individual_results = []
        individual_total_time = 0
        
        for db_file in self.db_files:
            gc.collect()  # ê° íŒŒì¼ ì²˜ë¦¬ ì „ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            result = self.convert_single_db_to_code(db_file)
            if result['success']:
                individual_results.append(result)
                individual_total_time += result['execution_time']
        
        # ì¼ê´„ ì²˜ë¦¬ ì„±ëŠ¥ ì¸¡ì •
        print("\nğŸ”„ ì¼ê´„ ì²˜ë¦¬ ì„±ëŠ¥ ì¸¡ì •")
        gc.collect()  # ì¼ê´„ ì²˜ë¦¬ ì „ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        batch_result = self.convert_batch_db_to_code(self.db_files)
        
        # ì„±ëŠ¥ ë¹„êµ ë¶„ì„
        comparison = {
            'individual_results': individual_results,
            'batch_result': batch_result,
            'performance_comparison': {}
        }
        
        if individual_results and batch_result['success']:
            individual_avg_time = individual_total_time / len(individual_results)
            batch_total_time = batch_result['execution_time']
            
            individual_total_items = sum(r['processed_items'] for r in individual_results)
            batch_total_items = batch_result['processed_items']
            
            individual_total_memory = sum(r['memory_delta_mb'] for r in individual_results)
            batch_total_memory = batch_result['memory_delta_mb']
            
            # ì„±ëŠ¥ ë¹„êµ ì§€í‘œ
            time_efficiency = individual_total_time / batch_total_time if batch_total_time > 0 else 0
            memory_efficiency = individual_total_memory / batch_total_memory if batch_total_memory > 0 else 0
            
            comparison['performance_comparison'] = {
                'individual_total_time': individual_total_time,
                'individual_avg_time': individual_avg_time,
                'batch_total_time': batch_total_time,
                'time_efficiency_ratio': time_efficiency,
                'individual_total_items': individual_total_items,
                'batch_total_items': batch_total_items,
                'individual_total_memory_mb': individual_total_memory,
                'batch_total_memory_mb': batch_total_memory,
                'memory_efficiency_ratio': memory_efficiency
            }
            
            print(f"\nğŸ“ˆ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼:")
            print(f"   ê°œë³„ ì²˜ë¦¬ ì´ ì‹œê°„: {individual_total_time:.3f}ì´ˆ")
            print(f"   ì¼ê´„ ì²˜ë¦¬ ì´ ì‹œê°„: {batch_total_time:.3f}ì´ˆ")
            print(f"   ì‹œê°„ íš¨ìœ¨ì„±: {time_efficiency:.2f}ë°° ({'ì¼ê´„ì´ ë¹ ë¦„' if time_efficiency > 1 else 'ê°œë³„ì´ ë¹ ë¦„'})")
            print(f"   ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±: {memory_efficiency:.2f}ë°°")
            
            if time_efficiency < 1:
                performance_loss = (1 - time_efficiency) * 100
                print(f"   âš ï¸ ì¼ê´„ ì²˜ë¦¬ ì„±ëŠ¥ ì €í•˜: {performance_loss:.1f}%")
            else:
                performance_gain = (time_efficiency - 1) * 100
                print(f"   âœ… ì¼ê´„ ì²˜ë¦¬ ì„±ëŠ¥ í–¥ìƒ: {performance_gain:.1f}%")
        
        return comparison

if __name__ == "__main__":
    print("ğŸ” DB â†’ C ì½”ë“œ ë³€í™˜ ì„±ëŠ¥ ë¬¸ì œ ë¶„ì„")
    print("=" * 80)
    
    analyzer = DBToCodePerformanceAnalyzer()
    
    # DB íŒŒì¼ ë°œê²¬
    db_files = analyzer.discover_db_files()
    
    if not db_files:
        print("âŒ ë¶„ì„í•  DB íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    # ì„±ëŠ¥ ë¹„êµ ì‹¤í–‰
    comparison_results = analyzer.compare_performance()
    
    # ê²°ê³¼ ì €ì¥
    with open('db_to_code_performance_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(comparison_results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“„ ìƒì„¸ ë¶„ì„ ê²°ê³¼ê°€ 'db_to_code_performance_analysis.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("=" * 80)
