"""
DB ‚Üí C ÏΩîÎìú Î≥ÄÌôò ÏÑ±Îä• Î¨∏Ï†ú Î∂ÑÏÑùÍ∏∞
ÏùºÍ¥Ñ Ï≤òÎ¶¨ vs Í∞úÎ≥Ñ Ï≤òÎ¶¨ ÏÑ±Îä• ÎπÑÍµê Î∞è Î≥ëÎ™© ÏßÄÏ†ê ÏãùÎ≥Ñ
"""

import time
import psutil
import gc
import logging
import os
import sys
from pathlib import Path
from typing import Dict, List, Any, Tuple
import json
import traceback
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import threading

# ÌîÑÎ°úÏ†ùÌä∏ Î£®Ìä∏ Í≤ΩÎ°ú ÏÑ§Ï†ï
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# Î°úÍπÖ ÏÑ§Ï†ï
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-8s | %(message)s'
)

class DBToCodePerformanceAnalyzer:
    """DB ‚Üí C ÏΩîÎìú Î≥ÄÌôò ÏÑ±Îä• Î∂ÑÏÑùÍ∏∞"""
    
    def __init__(self):
        self.process = psutil.Process()
        self.analysis_results = {}
        self.db_files = []
        
    def discover_db_files(self) -> List[Path]:
        """DB ÌååÏùº Î∞úÍ≤¨ Î∞è Î∂ÑÏÑù"""
        print("üîç DB ÌååÏùº Î∞úÍ≤¨ Î∞è Î∂ÑÏÑù")
        print("=" * 60)
        
        db_dir = Path('database')
        if not db_dir.exists():
            print("‚ùå Database ÎîîÎ†âÌÜ†Î¶¨Í∞Ä Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§.")
            return []
        
        db_files = list(db_dir.glob('*.db'))
        print(f"üìÅ Î∞úÍ≤¨Îêú DB ÌååÏùº: {len(db_files)}Í∞ú")
        
        # DB ÌååÏùº ÏÉÅÏÑ∏ Ï†ïÎ≥¥ Î∂ÑÏÑù
        for i, db_file in enumerate(db_files):
            file_size = db_file.stat().st_size
            print(f"   {i+1}. {db_file.name} ({file_size:,} bytes)")
            
            # DB ÎÇ¥Ïö© Í∞ÑÎã® Î∂ÑÏÑù
            try:
                from data_manager.db_handler_v2 import DBHandlerV2
                db_handler = DBHandlerV2(str(db_file))
                db_handler.connect()
                
                sheets = db_handler.get_sheets()
                dollar_sheets = [s for s in sheets if s.get('is_dollar_sheet', False)]
                
                total_cells = 0
                for sheet in dollar_sheets:
                    sheet_data = db_handler.get_sheet_data(sheet['id'])
                    if sheet_data:
                        total_cells += len(sheet_data)
                
                print(f"      ÏãúÌä∏: {len(sheets)}Í∞ú ($ ÏãúÌä∏: {len(dollar_sheets)}Í∞ú)")
                print(f"      ÏÖÄ Îç∞Ïù¥ÌÑ∞: {total_cells:,}Í∞ú")
                
                db_handler.disconnect()
                
            except Exception as e:
                print(f"      ‚ùå Î∂ÑÏÑù Ïã§Ìå®: {e}")
        
        self.db_files = db_files[:5]  # ÏµúÎåÄ 5Í∞ú ÌååÏùº
        return self.db_files
    
    def measure_memory_and_cpu(self) -> Dict[str, float]:
        """Î©îÎ™®Î¶¨ Î∞è CPU ÏÇ¨Ïö©Îüâ Ï∏°Ï†ï"""
        memory_info = self.process.memory_info()
        cpu_percent = self.process.cpu_percent()
        
        return {
            'rss_mb': memory_info.rss / 1024 / 1024,
            'vms_mb': memory_info.vms / 1024 / 1024,
            'cpu_percent': cpu_percent
        }
    
    def convert_single_db_to_code(self, db_file: Path) -> Dict[str, Any]:
        """Îã®Ïùº DB ÌååÏùºÏùÑ C ÏΩîÎìúÎ°ú Î≥ÄÌôò"""
        print(f"\nüîÑ Îã®Ïùº Î≥ÄÌôò: {db_file.name}")
        
        start_memory = self.measure_memory_and_cpu()
        start_time = time.perf_counter()
        
        try:
            from data_manager.db_handler_v2 import DBHandlerV2
            from cython_extensions.code_generator_v2 import fast_write_cal_list_processing
            
            # DB Ïó∞Í≤∞
            db_handler = DBHandlerV2(str(db_file))
            db_handler.connect()
            
            # $ ÏãúÌä∏ Ï∞æÍ∏∞
            sheets = db_handler.get_sheets()
            dollar_sheets = [s for s in sheets if s.get('is_dollar_sheet', False)]
            
            total_processed_items = 0
            step_times = {}
            
            # Îã®Í≥ÑÎ≥Ñ ÏãúÍ∞Ñ Ï∏°Ï†ï
            step_start = time.perf_counter()
            
            for sheet in dollar_sheets:
                sheet_data = db_handler.get_sheet_data(sheet['id'])
                if sheet_data:
                    # ÏΩîÎìú ÏïÑÏù¥ÌÖú ÏÉùÏÑ±
                    code_items = []
                    for row_data in sheet_data:
                        if len(row_data) >= 3:
                            code_items.append([
                                "DEFINE", "CONST", "FLOAT32",
                                f"VAL_{row_data[0]}_{row_data[1]}", 
                                str(row_data[2]) if row_data[2] else "",
                                f"Generated from {sheet['name']}"
                            ])
                    
                    # Cython ÏΩîÎìú ÏÉùÏÑ±
                    processed_code = fast_write_cal_list_processing(code_items)
                    total_processed_items += len(processed_code)
            
            step_times['code_generation'] = time.perf_counter() - step_start
            
            # DB Ïó∞Í≤∞ Ìï¥Ï†ú
            db_handler.disconnect()
            
            end_time = time.perf_counter()
            end_memory = self.measure_memory_and_cpu()
            
            execution_time = end_time - start_time
            memory_delta = end_memory['rss_mb'] - start_memory['rss_mb']
            
            result = {
                'success': True,
                'execution_time': execution_time,
                'processed_items': total_processed_items,
                'memory_delta_mb': memory_delta,
                'start_memory_mb': start_memory['rss_mb'],
                'end_memory_mb': end_memory['rss_mb'],
                'step_times': step_times,
                'file_name': db_file.name
            }
            
            print(f"   ‚úÖ ÏôÑÎ£å: {execution_time:.3f}Ï¥à, {total_processed_items:,}Í∞ú Ìï≠Î™©")
            print(f"   üìä Î©îÎ™®Î¶¨: {start_memory['rss_mb']:.1f}MB ‚Üí {end_memory['rss_mb']:.1f}MB (+{memory_delta:.1f}MB)")
            
            return result
            
        except Exception as e:
            print(f"   ‚ùå Ïã§Ìå®: {e}")
            return {
                'success': False,
                'error': str(e),
                'file_name': db_file.name
            }
    
    def convert_batch_db_to_code(self, db_files: List[Path]) -> Dict[str, Any]:
        """ÏùºÍ¥Ñ DB ÌååÏùºÏùÑ C ÏΩîÎìúÎ°ú Î≥ÄÌôò"""
        print(f"\nüîÑ ÏùºÍ¥Ñ Î≥ÄÌôò: {len(db_files)}Í∞ú ÌååÏùº")
        
        start_memory = self.measure_memory_and_cpu()
        start_time = time.perf_counter()
        
        try:
            from data_manager.db_handler_v2 import DBHandlerV2
            from cython_extensions.code_generator_v2 import fast_write_cal_list_processing
            
            total_processed_items = 0
            file_results = []
            step_times = {}
            
            for i, db_file in enumerate(db_files):
                file_start_time = time.perf_counter()
                file_start_memory = self.measure_memory_and_cpu()
                
                print(f"   üìÅ Ï≤òÎ¶¨ Ï§ë ({i+1}/{len(db_files)}): {db_file.name}")
                
                # DB Ïó∞Í≤∞
                db_handler = DBHandlerV2(str(db_file))
                db_handler.connect()
                
                # $ ÏãúÌä∏ Ï∞æÍ∏∞
                sheets = db_handler.get_sheets()
                dollar_sheets = [s for s in sheets if s.get('is_dollar_sheet', False)]
                
                file_processed_items = 0
                
                for sheet in dollar_sheets:
                    sheet_data = db_handler.get_sheet_data(sheet['id'])
                    if sheet_data:
                        # ÏΩîÎìú ÏïÑÏù¥ÌÖú ÏÉùÏÑ±
                        code_items = []
                        for row_data in sheet_data:
                            if len(row_data) >= 3:
                                code_items.append([
                                    "DEFINE", "CONST", "FLOAT32",
                                    f"VAL_{row_data[0]}_{row_data[1]}", 
                                    str(row_data[2]) if row_data[2] else "",
                                    f"Generated from {sheet['name']}"
                                ])
                        
                        # Cython ÏΩîÎìú ÏÉùÏÑ±
                        processed_code = fast_write_cal_list_processing(code_items)
                        file_processed_items += len(processed_code)
                
                # DB Ïó∞Í≤∞ Ìï¥Ï†ú
                db_handler.disconnect()
                
                file_end_time = time.perf_counter()
                file_end_memory = self.measure_memory_and_cpu()
                
                file_execution_time = file_end_time - file_start_time
                file_memory_delta = file_end_memory['rss_mb'] - file_start_memory['rss_mb']
                
                file_results.append({
                    'file_name': db_file.name,
                    'execution_time': file_execution_time,
                    'processed_items': file_processed_items,
                    'memory_delta_mb': file_memory_delta
                })
                
                total_processed_items += file_processed_items
                
                print(f"      ‚úÖ {file_execution_time:.3f}Ï¥à, {file_processed_items:,}Í∞ú Ìï≠Î™©, Î©îÎ™®Î¶¨ +{file_memory_delta:.1f}MB")
                
                # Ï§ëÍ∞Ñ Í∞ÄÎπÑÏßÄ Ïª¨Î†âÏÖò
                gc.collect()
            
            end_time = time.perf_counter()
            end_memory = self.measure_memory_and_cpu()
            
            execution_time = end_time - start_time
            memory_delta = end_memory['rss_mb'] - start_memory['rss_mb']
            
            result = {
                'success': True,
                'execution_time': execution_time,
                'processed_items': total_processed_items,
                'memory_delta_mb': memory_delta,
                'start_memory_mb': start_memory['rss_mb'],
                'end_memory_mb': end_memory['rss_mb'],
                'file_results': file_results,
                'files_count': len(db_files)
            }
            
            print(f"\n   ‚úÖ ÏùºÍ¥Ñ Î≥ÄÌôò ÏôÑÎ£å: {execution_time:.3f}Ï¥à")
            print(f"   üìä Ï¥ù Ï≤òÎ¶¨: {total_processed_items:,}Í∞ú Ìï≠Î™©")
            print(f"   üìä Î©îÎ™®Î¶¨: {start_memory['rss_mb']:.1f}MB ‚Üí {end_memory['rss_mb']:.1f}MB (+{memory_delta:.1f}MB)")
            
            return result
            
        except Exception as e:
            print(f"   ‚ùå ÏùºÍ¥Ñ Î≥ÄÌôò Ïã§Ìå®: {e}")
            return {
                'success': False,
                'error': str(e),
                'files_count': len(db_files)
            }
    
    def compare_performance(self) -> Dict[str, Any]:
        """Í∞úÎ≥Ñ vs ÏùºÍ¥Ñ Ï≤òÎ¶¨ ÏÑ±Îä• ÎπÑÍµê"""
        print("\nüìä Í∞úÎ≥Ñ vs ÏùºÍ¥Ñ Ï≤òÎ¶¨ ÏÑ±Îä• ÎπÑÍµê")
        print("=" * 60)
        
        if not self.db_files:
            print("‚ùå Î∂ÑÏÑùÌï† DB ÌååÏùºÏù¥ ÏóÜÏäµÎãàÎã§.")
            return {}
        
        # Í∞úÎ≥Ñ Ï≤òÎ¶¨ ÏÑ±Îä• Ï∏°Ï†ï
        print("\nüîÑ Í∞úÎ≥Ñ Ï≤òÎ¶¨ ÏÑ±Îä• Ï∏°Ï†ï")
        individual_results = []
        individual_total_time = 0
        
        for db_file in self.db_files:
            gc.collect()  # Í∞Å ÌååÏùº Ï≤òÎ¶¨ Ï†Ñ Í∞ÄÎπÑÏßÄ Ïª¨Î†âÏÖò
            result = self.convert_single_db_to_code(db_file)
            if result['success']:
                individual_results.append(result)
                individual_total_time += result['execution_time']
        
        # ÏùºÍ¥Ñ Ï≤òÎ¶¨ ÏÑ±Îä• Ï∏°Ï†ï
        print("\nüîÑ ÏùºÍ¥Ñ Ï≤òÎ¶¨ ÏÑ±Îä• Ï∏°Ï†ï")
        gc.collect()  # ÏùºÍ¥Ñ Ï≤òÎ¶¨ Ï†Ñ Í∞ÄÎπÑÏßÄ Ïª¨Î†âÏÖò
        batch_result = self.convert_batch_db_to_code(self.db_files)
        
        # ÏÑ±Îä• ÎπÑÍµê Î∂ÑÏÑù
        comparison = {
            'individual_results': individual_results,
            'batch_result': batch_result,
            'performance_comparison': {}
        }
        
        if individual_results and batch_result['success']:
            individual_avg_time = individual_total_time / len(individual_results)
            batch_total_time = batch_result['execution_time']
            
            individual_total_items = sum(r['processed_items'] for r in individual_results)
            batch_total_items = batch_result['processed_items']
            
            individual_total_memory = sum(r['memory_delta_mb'] for r in individual_results)
            batch_total_memory = batch_result['memory_delta_mb']
            
            # ÏÑ±Îä• ÎπÑÍµê ÏßÄÌëú
            time_efficiency = individual_total_time / batch_total_time if batch_total_time > 0 else 0
            memory_efficiency = individual_total_memory / batch_total_memory if batch_total_memory > 0 else 0
            
            comparison['performance_comparison'] = {
                'individual_total_time': individual_total_time,
                'individual_avg_time': individual_avg_time,
                'batch_total_time': batch_total_time,
                'time_efficiency_ratio': time_efficiency,
                'individual_total_items': individual_total_items,
                'batch_total_items': batch_total_items,
                'individual_total_memory_mb': individual_total_memory,
                'batch_total_memory_mb': batch_total_memory,
                'memory_efficiency_ratio': memory_efficiency
            }
            
            print(f"\nüìà ÏÑ±Îä• ÎπÑÍµê Í≤∞Í≥º:")
            print(f"   Í∞úÎ≥Ñ Ï≤òÎ¶¨ Ï¥ù ÏãúÍ∞Ñ: {individual_total_time:.3f}Ï¥à")
            print(f"   ÏùºÍ¥Ñ Ï≤òÎ¶¨ Ï¥ù ÏãúÍ∞Ñ: {batch_total_time:.3f}Ï¥à")
            print(f"   ÏãúÍ∞Ñ Ìö®Ïú®ÏÑ±: {time_efficiency:.2f}Î∞∞ ({'ÏùºÍ¥ÑÏù¥ Îπ†Î¶Ñ' if time_efficiency > 1 else 'Í∞úÎ≥ÑÏù¥ Îπ†Î¶Ñ'})")
            print(f"   Î©îÎ™®Î¶¨ Ìö®Ïú®ÏÑ±: {memory_efficiency:.2f}Î∞∞")
            
            if time_efficiency < 1:
                performance_loss = (1 - time_efficiency) * 100
                print(f"   ‚ö†Ô∏è ÏùºÍ¥Ñ Ï≤òÎ¶¨ ÏÑ±Îä• Ï†ÄÌïò: {performance_loss:.1f}%")
            else:
                performance_gain = (time_efficiency - 1) * 100
                print(f"   ‚úÖ ÏùºÍ¥Ñ Ï≤òÎ¶¨ ÏÑ±Îä• Ìñ•ÏÉÅ: {performance_gain:.1f}%")
        
        return comparison

if __name__ == "__main__":
    print("üîç DB ‚Üí C ÏΩîÎìú Î≥ÄÌôò ÏÑ±Îä• Î¨∏Ï†ú Î∂ÑÏÑù")
    print("=" * 80)
    
    analyzer = DBToCodePerformanceAnalyzer()
    
    # DB ÌååÏùº Î∞úÍ≤¨
    db_files = analyzer.discover_db_files()
    
    if not db_files:
        print("‚ùå Î∂ÑÏÑùÌï† DB ÌååÏùºÏù¥ ÏóÜÏäµÎãàÎã§.")
        sys.exit(1)
    
    # ÏÑ±Îä• ÎπÑÍµê Ïã§Ìñâ
    comparison_results = analyzer.compare_performance()
    
    # Í≤∞Í≥º Ï†ÄÏû•
    with open('db_to_code_performance_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(comparison_results, f, indent=2, ensure_ascii=False)
    
    print(f"\nüìÑ ÏÉÅÏÑ∏ Î∂ÑÏÑù Í≤∞Í≥ºÍ∞Ä 'db_to_code_performance_analysis.json'Ïóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.")
    print("=" * 80)
