"""
UI ì‹œìŠ¤í…œê³¼ Phase 3 ë°±ì—”ë“œ ìµœì í™” í†µí•© ì „ëµ
ê¸°ì¡´ GUIë¥¼ ìœ ì§€í•˜ë©´ì„œ ë°±ì—”ë“œ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë°©ì•ˆ
"""

import sys
import time
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

@dataclass
class IntegrationConfig:
    """í†µí•© ì„¤ì •"""
    enable_async_processing: bool = True
    enable_distributed_processing: bool = True
    enable_caching: bool = True
    auto_optimization: bool = True
    ui_progress_updates: bool = True
    background_processing: bool = True

class Phase3BackendIntegrator:
    """Phase 3 ë°±ì—”ë“œ ìµœì í™”ë¥¼ UI ì‹œìŠ¤í…œì— í†µí•©í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, config: IntegrationConfig = None):
        self.config = config or IntegrationConfig()
        self.logger = logging.getLogger(__name__)
        
        # Phase 3 í”„ë¡œì„¸ì„œë“¤ ì´ˆê¸°í™”
        self._async_processor = None
        self._distributed_processor = None
        self._cached_processor = None
        
    def initialize_processors(self):
        """Phase 3 í”„ë¡œì„¸ì„œë“¤ ì´ˆê¸°í™”"""
        try:
            if self.config.enable_async_processing:
                from async_db_processor import AsyncDBProcessor, AsyncConfig
                async_config = AsyncConfig(
                    batch_size=500,
                    chunk_size=1000,
                    max_concurrent_dbs=8,
                    max_concurrent_sheets=16
                )
                self._async_processor = AsyncDBProcessor(async_config)
                self.logger.info("âœ… ë¹„ë™ê¸° í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì™„ë£Œ")
            
            if self.config.enable_distributed_processing:
                from distributed_db_processor import DistributedDBProcessor, DistributedConfig
                distributed_config = DistributedConfig(
                    batch_size=500,
                    chunk_size=1000,
                    max_processes=4,
                    worker_timeout=300.0,
                    memory_limit_mb=512
                )
                self._distributed_processor = DistributedDBProcessor(distributed_config)
                self.logger.info("âœ… ë¶„ì‚° í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì™„ë£Œ")
            
            if self.config.enable_caching:
                from cached_db_processor import CachedDBProcessor, CacheConfig
                cache_config = CacheConfig(
                    batch_size=500,
                    chunk_size=500,
                    enable_memory_cache=True,
                    memory_cache_size=5000,
                    enable_redis_cache=False  # UI í™˜ê²½ì—ì„œëŠ” ë©”ëª¨ë¦¬ ìºì‹œë§Œ ì‚¬ìš©
                )
                self._cached_processor = CachedDBProcessor(cache_config)
                self.logger.info("âœ… ìºì‹± í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì™„ë£Œ")
                
        except Exception as e:
            self.logger.error(f"Phase 3 í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def choose_optimal_processor(self, db_files: List[Path]) -> str:
        """ìƒí™©ë³„ ìµœì  í”„ë¡œì„¸ì„œ ì„ íƒ (UI í™˜ê²½ ê³ ë ¤)"""
        if not db_files:
            return "none"
        
        file_count = len(db_files)
        total_size = sum(f.stat().st_size for f in db_files if f.exists())
        avg_size = total_size / file_count if file_count > 0 else 0
        
        # UI í™˜ê²½ì—ì„œëŠ” ì•ˆì •ì„±ì„ ìš°ì„ ì‹œ
        if file_count >= 4 and avg_size > 500000:  # 500KB ì´ìƒì˜ í° íŒŒì¼ë“¤
            if self.config.enable_async_processing and self._async_processor:
                return "async"
            elif self.config.enable_distributed_processing and self._distributed_processor:
                return "distributed"
        elif file_count >= 2:
            if self.config.enable_caching and self._cached_processor:
                return "cached"
        
        return "sequential"  # ê¸°ë³¸ ì²˜ë¦¬
    
    async def process_db_files_optimized(self, db_files: List[Path], 
                                       progress_callback=None) -> Dict[str, Any]:
        """ìµœì í™”ëœ DB íŒŒì¼ ì²˜ë¦¬ (UI ì§„í–‰ë¥  ì½œë°± ì§€ì›)"""
        if not db_files:
            return {'success': False, 'error': 'No DB files provided'}
        
        # ìµœì  í”„ë¡œì„¸ì„œ ì„ íƒ
        processor_type = self.choose_optimal_processor(db_files)
        
        if progress_callback:
            progress_callback(0, f"ì²˜ë¦¬ ëª¨ë“œ ì„ íƒ: {processor_type}")
        
        try:
            if processor_type == "async" and self._async_processor:
                result = await self._async_processor.process_batch_async(db_files)
                result['processor_type'] = 'async'
                
            elif processor_type == "distributed" and self._distributed_processor:
                if progress_callback:
                    progress_callback(10, "ë¶„ì‚° ì²˜ë¦¬ ì‹œì‘...")
                result = self._distributed_processor.process_batch_distributed(db_files)
                result['processor_type'] = 'distributed'
                
            elif processor_type == "cached" and self._cached_processor:
                if progress_callback:
                    progress_callback(10, "ìºì‹œ ì²˜ë¦¬ ì‹œì‘...")
                result = self._cached_processor.process_batch_cached(db_files)
                result['processor_type'] = 'cached'
                
            else:
                # ê¸°ë³¸ ìˆœì°¨ ì²˜ë¦¬
                if progress_callback:
                    progress_callback(10, "ìˆœì°¨ ì²˜ë¦¬ ì‹œì‘...")
                result = await self._process_sequential(db_files, progress_callback)
                result['processor_type'] = 'sequential'
            
            if progress_callback:
                progress_callback(100, "ì²˜ë¦¬ ì™„ë£Œ")
            
            return result
            
        except Exception as e:
            self.logger.error(f"DB íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'processor_type': processor_type
            }
    
    async def _process_sequential(self, db_files: List[Path], 
                                progress_callback=None) -> Dict[str, Any]:
        """ê¸°ë³¸ ìˆœì°¨ ì²˜ë¦¬ (UI ì§„í–‰ë¥  ì§€ì›)"""
        from production_ready_db_processor import ProductionDBProcessor, ProductionConfig
        
        config = ProductionConfig(
            batch_size=500,
            chunk_size=1000,
            enable_parallel_processing=False
        )
        
        processor = ProductionDBProcessor(config)
        
        try:
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ë˜í¼
            if progress_callback:
                total_files = len(db_files)
                for i, db_file in enumerate(db_files):
                    progress = 20 + (i * 60 // total_files)
                    progress_callback(progress, f"ì²˜ë¦¬ ì¤‘: {db_file.name}")
            
            result = processor.process_batch_production(db_files)
            return result
            
        finally:
            processor.cleanup()
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            if self._async_processor:
                # ë¹„ë™ê¸° í”„ë¡œì„¸ì„œëŠ” ë³„ë„ ì •ë¦¬ í•„ìš”
                import asyncio
                if asyncio.get_event_loop().is_running():
                    asyncio.create_task(self._async_processor.cleanup())
                else:
                    asyncio.run(self._async_processor.cleanup())
            
            if self._cached_processor:
                self._cached_processor.cleanup()
                
            # ë¶„ì‚° í”„ë¡œì„¸ì„œëŠ” ìë™ ì •ë¦¬ë¨
            
            self.logger.info("Phase 3 ë°±ì—”ë“œ í†µí•© ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")

class UIProgressHandler:
    """UI ì§„í–‰ë¥  ì²˜ë¦¬ í—¬í¼ í´ë˜ìŠ¤"""
    
    def __init__(self, progress_bar=None, status_label=None):
        self.progress_bar = progress_bar
        self.status_label = status_label
    
    def update_progress(self, percentage: int, message: str = ""):
        """ì§„í–‰ë¥  ì—…ë°ì´íŠ¸"""
        if self.progress_bar:
            self.progress_bar.setValue(percentage)
        
        if self.status_label and message:
            self.status_label.setText(message)
    
    def __call__(self, percentage: int, message: str = ""):
        """ì½œë°±ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í˜¸ì¶œ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¦"""
        self.update_progress(percentage, message)

# UI í†µí•©ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜ë“¤
def integrate_phase3_to_ui_method(ui_class, method_name: str):
    """
    ê¸°ì¡´ UI í´ë˜ìŠ¤ì˜ ë©”ì„œë“œì— Phase 3 ìµœì í™”ë¥¼ í†µí•©í•˜ëŠ” ë°ì½”ë ˆì´í„°
    
    ì‚¬ìš© ì˜ˆ:
    @integrate_phase3_to_ui_method(DBExcelEditor, 'process_excel_files')
    def optimized_process_excel_files(self, files):
        # Phase 3 ìµœì í™”ê°€ ì ìš©ëœ ì²˜ë¦¬
        pass
    """
    def decorator(optimized_func):
        # ì›ë³¸ ë©”ì„œë“œ ë°±ì—…
        original_method = getattr(ui_class, method_name, None)
        if original_method:
            setattr(ui_class, f'_original_{method_name}', original_method)
        
        # ìµœì í™”ëœ ë©”ì„œë“œë¡œ êµì²´
        setattr(ui_class, method_name, optimized_func)
        
        return optimized_func
    
    return decorator

def create_background_processor():
    """ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ìš© Phase 3 í†µí•© í”„ë¡œì„¸ì„œ ìƒì„±"""
    config = IntegrationConfig(
        enable_async_processing=True,
        enable_distributed_processing=True,
        enable_caching=True,
        auto_optimization=True,
        ui_progress_updates=True,
        background_processing=True
    )

    integrator = Phase3BackendIntegrator(config)
    integrator.initialize_processors()

    return integrator

def inject_phase3_into_existing_class(target_class):
    """ê¸°ì¡´ í´ë˜ìŠ¤ì— Phase 3 ê¸°ëŠ¥ì„ ì£¼ì…í•˜ëŠ” í•¨ìˆ˜"""

    # Phase 3 ì´ˆê¸°í™” ë©”ì„œë“œ ì¶”ê°€
    def init_phase3_backend(self):
        """Phase 3 ë°±ì—”ë“œ ì´ˆê¸°í™”"""
        try:
            self.phase3_backend = create_background_processor()
            self.phase3_enabled = True
            logging.info("âœ… Phase 3 ë°±ì—”ë“œ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            self.phase3_backend = None
            self.phase3_enabled = False
            logging.warning(f"âš ï¸ Phase 3 ë°±ì—”ë“œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    # Phase 3 ì²˜ë¦¬ ë©”ì„œë“œ ì¶”ê°€
    async def process_with_phase3_optimization(self, db_files):
        """Phase 3 ìµœì í™”ëœ ì²˜ë¦¬"""
        if not hasattr(self, 'phase3_backend') or not self.phase3_backend:
            return None

        try:
            result = await self.phase3_backend.process_db_files_optimized(db_files)
            return result
        except Exception as e:
            logging.error(f"Phase 3 ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None

    # ê¸°ì¡´ ë©”ì„œë“œ í™•ì¥ì„ ìœ„í•œ í—¬í¼ ë©”ì„œë“œ
    def enhance_existing_method(self, method_name, enhancement_func):
        """ê¸°ì¡´ ë©”ì„œë“œë¥¼ Phase 3 ìµœì í™”ë¡œ í™•ì¥"""
        if hasattr(self, method_name):
            original_method = getattr(self, method_name)

            def enhanced_method(*args, **kwargs):
                # ê¸°ì¡´ ë©”ì„œë“œ ì‹¤í–‰
                original_result = original_method(*args, **kwargs)

                # Phase 3 ìµœì í™” ì ìš©
                if hasattr(self, 'phase3_enabled') and self.phase3_enabled:
                    try:
                        enhanced_result = enhancement_func(self, original_result, *args, **kwargs)
                        return enhanced_result if enhanced_result is not None else original_result
                    except Exception as e:
                        logging.warning(f"Phase 3 í™•ì¥ ì‹¤íŒ¨, ê¸°ì¡´ ê²°ê³¼ ë°˜í™˜: {e}")
                        return original_result

                return original_result

            setattr(self, method_name, enhanced_method)

    # ê¸°ì¡´ í´ë˜ìŠ¤ì— ë©”ì„œë“œ ì¶”ê°€
    target_class.init_phase3_backend = init_phase3_backend
    target_class.process_with_phase3_optimization = process_with_phase3_optimization

    # ê¸°ì¡´ __init__ ë©”ì„œë“œ í™•ì¥
    original_init = target_class.__init__

    def enhanced_init(self, *args, **kwargs):
        # ê¸°ì¡´ ì´ˆê¸°í™” ì‹¤í–‰
        original_init(self, *args, **kwargs)

        # Phase 3 ë°±ì—”ë“œ ì´ˆê¸°í™” ì¶”ê°€
        try:
            self.init_phase3_backend()
        except Exception as e:
            logging.warning(f"Phase 3 ë°±ì—”ë“œ ì´ˆê¸°í™” ê±´ë„ˆë›°ê¸°: {e}")

    target_class.__init__ = enhanced_init

    return target_class

# ì‚¬ìš© ì˜ˆì‹œ
def example_ui_integration():
    """UI í†µí•© ì‚¬ìš© ì˜ˆì‹œ"""
    
    # 1. ë°±ê·¸ë¼ìš´ë“œ í”„ë¡œì„¸ì„œ ìƒì„±
    backend_processor = create_background_processor()
    
    # 2. UI ì§„í–‰ë¥  í•¸ë“¤ëŸ¬ ìƒì„± (ì‹¤ì œ UI ìœ„ì ¯ê³¼ ì—°ê²°)
    # progress_handler = UIProgressHandler(progress_bar, status_label)
    
    # 3. DB íŒŒì¼ ì²˜ë¦¬ (ë¹„ë™ê¸°)
    # result = await backend_processor.process_db_files_optimized(
    #     db_files, progress_callback=progress_handler
    # )
    
    # 4. ê²°ê³¼ ì²˜ë¦¬
    # if result['success']:
    #     print(f"ì²˜ë¦¬ ì™„ë£Œ: {result['processor_type']} ëª¨ë“œ")
    # else:
    #     print(f"ì²˜ë¦¬ ì‹¤íŒ¨: {result['error']}")
    
    # 5. ì •ë¦¬
    # backend_processor.cleanup()
    
    pass

if __name__ == "__main__":
    # í†µí•© ì „ëµ í…ŒìŠ¤íŠ¸
    print("ğŸ”§ UI-ë°±ì—”ë“œ í†µí•© ì „ëµ ëª¨ë“ˆ")
    print("   Phase 3 ìµœì í™”ë¥¼ ê¸°ì¡´ UIì— í†µí•©í•˜ëŠ” ë°©ì•ˆ ì œê³µ")
    
    # ì„¤ì • ì˜ˆì‹œ
    config = IntegrationConfig(
        enable_async_processing=True,
        enable_distributed_processing=True,
        enable_caching=True,
        auto_optimization=True
    )
    
    print(f"   ì„¤ì •: {config}")
    print("   ì‚¬ìš©ë²•: create_background_processor() í•¨ìˆ˜ í™œìš©")
